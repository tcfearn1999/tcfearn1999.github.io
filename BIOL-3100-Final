```markdown
# Project: CNN for Microbial Community Assembly Classification

## Introduction

This project aims to develop a CNN in R capable of classifying ecological processes that govern microbial community assembly. The current stage is identifying between *antagonism* and *stochasticity*.

## Background

This project emerged from research on the microbiomes of Mangroves in Southeast Asia. These plants have been threatened by development, and recent efforts have focused on transplanting them into sanctuaries, protected lands, and new suitable environments. It has been found that out-planting success is improved when transplanted with mutualistic microbes. Even though it increases the success rate of the plant living and thriving in the new environment, processes that govern the assembly of microbial communities are little understood. We can identify certain relationships between microbes on larger scales and observe these processes at play. However, the challenge arises when we have to analyze thousands of microbes and identify how their various relationships work together to produce the outcome. Currently, there are no computational techniques for modeling these interactions. In recent years, various neural network structures have proven successful at closely approximating the outcome of non-linear problems. Thus, this project seeks to use convolutional neural networks (CNNs) to identify and classify the relationships in microbial community matrices.

CNNs are a type of neural network that takes in spatially related data, utilizes an encoder structure to develop a latent representation of that image, and then employs a couple of classifying layers to classify the input image into the pre-determined classes.

The data generated for this project was using an R package called CommunityAssemblR. In this project, it was used to generate matrices of microbial communities with antagonistic and stochastic processes at play. For each, it generates a resident community and then a donor difference matrix. The donor difference matrix illustrates the difference in the donor microbial community. This data had to be preprocessed as it was not spatially related.

To spatially arrange the data, a python package called DeepInsight was used. It employs dimensionality reduction techniques to produce images of the microbial community data. It goes through every row in an input matrix and produces an image representation of it. Examples of these images are seen below:

*(Put images)*

These Images were saved as NumPy arrays and loaded in R. The first step involving R in this project was the loading and pre-processing of the data. The packages used in R to develop this network are based on Python libraries so they are a little bit different to work with compared to your typical R package. The libraries necessary to execute the following scripts are:

```R
# Code snippets
```

Reticulate will install a virtual environment on your machine, install Python, and use that to execute the script. Using the following command after loading.

```R
# Code snippets
```

A pseudo-random seed is set in order to guarantee reproducibility.

```R
# Code snippets
```

The next couple of functions go through the two directories in the data_directory and process each file. On each file, they take the trial number, determine if it’s antagonistic or stochastic, get the resident input, donor output, sample number, and append it to a data frame. The reason I did it this way is that each file has 100 rows with a trial number and sample number. In order to train my neural network, I need to input a resident input image and donor output image each with the same trial and sample number.

```R
# Code snippets
```

The output of these functions is further processed with the following lines of code. They remove NA’s, shuffle the dataset, split it into training and testing. They also one-hot encode the antagonistic and stochastic labels and transform the data into matrices with the appropriate dimensions.

```R
# Code snippets
```

The network is defined in the following code. It is based on a known network structure used in the [VGG-19](link). I have modified this by having it take in two inputs, the resident community and the output donor community. The network goes through each of these images and condenses the image information of the image into smaller and smaller matrices until it gets the latent representation, which is basically the most important patterns recognized in that image. The latent representation from both inputs is then combined and fed into a couple of dense layers that classify the output. Here is the code for the network

```R
# Code snippets
```

In training the network, there are a couple of parameters that you pick. The first is Epochs, which is how many times the neural network goes through all of the training data. The second is batch size, which refers to the size of chunks of data used in training the neural networks. The reason I included batch training is that it is shown to reduce overfitting as it ensures the data is not fed in the same order and reduces the risk of the network converging to a local minima instead of global maxima.

```R
# Code snippets
```

The results for this network were as follows after training it for 50 epochs:

### On Training Data:

- **Overall accuracy:**
  
  ![Overall accuracy graph](link)

- **F1-score:**
  
  ![F1-score graph](link)

- **Loss:**
  
  ![Loss graph](link)

- **Precision:**
  
  ![Precision graph](link)

- **Recall:**
  
  ![Recall graph](link)

### On Testing Data:

- **Overall accuracy:**
  
  ![Overall accuracy graph](link)

- **F1-score:**
  
  ![F1-score graph](link)

- **Loss:**
  
  ![Loss graph](link)

- **Precision:**
  
  ![Precision graph](link)

- **Recall:**
  
  ![Recall graph](link)

## Discussion

Discuss the results

## Conclusion

Tie everything together
